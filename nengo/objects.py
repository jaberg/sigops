import random
import warnings

import numpy as np

### High-level objects

class Uniform(object):
    def __init__(self, low, high):
        self.low = low
        self.high = high

    def __eq__(self, other):
        return self.low == other.low and self.high == other.high

    def sample(self, n):
        return [random.uniform(self.low, self.high) for _ in xrange(n)]


class Gaussian(object):
    def __init__(self, mean, std):
        self.mean = mean
        self.std = std

    def __eq__(self, other):
        return self.mean == other.mean and self.std == other.std

    def sample(self, n):
        return [random.gauss(self.mean, self.std) for _ in xrange(n)]


class Network(object):
    def __init__(self, name, seed, parent):
        self.model = model
        self.name = name

    def add(self, obj):
        pass

    def get(self, target, default=None):
        pass

    def remove(self, target):
        pass

    def connect(self, *args, **kwargs):
        pass

    def connect_neurons(self, *args, **kwargs):
        pass

    def make_alias(self, alias, target):
        pass

    def make_ensemble(self, *args, **kwargs):
        pass

    def make_network(self, *args, **kwargs):
        pass

    def make_node(self, *args, **kwargs):
        pass

    def probe(self, target, sample_every=None, static=False):
        pass


class Ensemble(object):
    """A collection of neurons that collectively represent a vector.

    Attributes
    ----------

    """
    def __init__(self, name, neurons, dimensions,
                 radius=1.0, encoders=None,
                 max_rates=Uniform(50, 100), intercepts=Uniform(-1, 1),
                 decoder_noise=None, eval_points=None,
                 noise=None, noise_frequency=None, seed=None):
        # Error for things not implemented yet or don't make sense
        if decoder_noise is not None:
            raise NotImplementedError('decoder_noise')
        if eval_points is not None:
            raise NotImplementedError('eval_points')
        if noise is not None or noise_frequency is not None:
            raise NotImplementedError('noise')
        if decoder_sign is not None:
            raise NotImplementedError('decoder_sign')

        if seed is None:
            seed = np.random.randint(1000)

        if isinstance(neurons, int):
            warnings.warn("neurons should be an instance of a nonlinearity, "
                          "not an int. Defaulting to LIF.")
            neurons = nl.LIF(neurons)

        # Look at arguments and expand those that need expanding
        if hasattr(max_rates, 'sample'):
            max_rates = max_rates.sample(neurons.n_neurons)
        if hasattr(intercepts, 'sample'):
            intercepts = intercepts.sample(neurons.n_neurons)

        # Store things on the ensemble that will be necessary for
        # later calculations or organization
        self.name = name
        self.radius = radius

        # The essential components of an ensemble are:
        #  self.signal - the signal (vector) being represented
        #  self.neurons - the neuron model representing the signal
        #  self.encoders - the encoders that map the signal into the population

        # Set up the signal
        self.signal = sim.Signal(n=dimensions)

        # Set up the neurons
        neurons.set_gain_bias(max_rates, intercepts)
        self.neurons = neurons

        # Set up the encoders
        self.encoders = sim.Encoder(self.sig, self.nl, encoders)

    def add_to_model(self, model):
        self.neurons.add_to_model(model)
        self.signal.add_to_model(model)
        self.encoders.add_to_model(model)

    def remove_from_model(self, model):
        raise NotImplementedError

    @property
    def n_neurons(self):
        return self.neurons.n_neurons

    @property
    def dimensions(self):
        return self.signal.n

class Node(object):
    """Provides arbitrary data to Nengo objects.

    It can also accept input, and perform arbitrary computations
    for the purpose of controlling a Nengo simulation.
    Nodes are typically not part of a brain model per se,
    but serve to summarize the assumptions being made
    about sensory data or other environment variables
    that cannot be generated by a brain model alone.
    Nodes are also useful to test models in various situations.

    Parameters
    ----------
    name : str
        Name of this node. Must be unique in the network.
    output : function, list of floats, dict, optional
        The output that should be generated by this node.

        If ``output`` is a function, it will be called on each timestep;
        if it accepts a single parameter, it will be given
        the current time of the simulation.

        If ``output`` is a list of floats, that list will be
        used as constant output.

        If ``output`` is a dict, the output defines a piece-wise constant
        function in which the keys define when the value changes,
        and the values define what the value changes to.

    Attributes
    ----------
    name : str
        A unique name that identifies the node.
    metadata : dict
        An editable dictionary that modelers can use to store
        extra information about a network.

    """

    def __init__(self, name, output, input):
        self.name = name
        if callable(output):
            self.nl = nl.Direct(n_in=1, n_out=1, fn=output)
            self.enc = sim.Encoder(input, self.nl, weights=np.asarray([[1]]))
            self.nl.input_signal.name = name + '.input'
            self.nl.bias_signal.name = name + '.bias'
            self.nl.output_signal.name = name + '.output'
            self.sig = self.nl.output_signal
        else:
            if type(output) == list:
                self.sig = sim.Constant(n=len(output),
                                       value=[float(n) for n in output])
            else:
                self.sig = sim.Constant(n=1, value=float(output))

    def __str__(self):
        if hasattr(self, 'nl'):
            return ("Function node (id " + str(id(self)) + "): \n"
                    "    " + str(self.nl) + "\n"
                    "    " + str(self.sig) + "\n"
                    "    " + str(self.enc))
        else:
            return ("Constant node (id " + str(id(self)) + "):  \n"
                    "    " + str(self.sig))

    def __repr__(self):
        return str(self)

    def add_to_model(self, model):
        if hasattr(self, 'nl'):
            model.nonlinearity(self.nl)
        if hasattr(self, 'enc'):
            model.encoders.add(self.enc)
            model.signals.add(self.enc.weights_signal)
        model.signals.add(self.sig)

    def remove_from_model(self, model):
        raise NotImplementedError


def sample_unit_signal(dimensions, num_samples, rng):
    """Generate sample points uniformly distributed within the sphere.

    Returns float array of sample points: dimensions x num_samples

    """
    samples = rng.randn(num_samples, dimensions)

    # normalize magnitude of sampled points to be of unit length
    norm = np.sum(samples * samples, axis=1)
    samples /= np.sqrt(norm)[:, None]

    # generate magnitudes for vectors from uniform distribution
    scale = rng.rand(num_samples, 1) ** (1.0 / dimensions)

    # scale sample points
    samples *= scale

    return samples.T


# -- James and Terry arrived at this by eyeballing some graphs.
#    Not clear if this should be a constant at all, it
#    may depend on fn being estimated, number of neurons, etc...
DEFAULT_RCOND=0.01

class Connection(object):
    """Describes a connection between two Nengo objects.

    The connection encapsulates a lot of information that Nengo needs
    to compute a biologically plausible connection between two networks
    that implements some mathematical function.
    Alternatively, the connection could bypass this logic and just store
    a set of connection weights between two Ensembles.

    Attributes
    ----------
    pre : Nengo object
        The Nengo object on the presynaptic side of this connection.
    post : Nengo object
        The Nengo object on the postsynaptic side of this connection.
    transform : 2D matrix of floats
        If the connection operates in vector (state) space,
        ``transform`` is a two-dimensional array of floats
        that represents the linear transformation
        between ``pre`` and ``post``.
    weights : 2D matrix of floats
        If the connection operates in neuron space,
        ``weights`` is a two-dimensional array of floats
        that represents the connection weights
        between ``pre`` neurons and ``post`` neurons.
    decoders : 2D matrix of floats
        If the connection operates in vector space,
        it will have a set of decoders defined that
        maps the neural activity to a vector representation.
    filter : dict
        A dictionary describing the filter that is applied to
        presynaptic spikes before being communicated to ``post``.
    function : function
        The function that this connection implements.
    learning_rule : dict
        A dictionary describing a learning rule that
        modifies connection's decoders, weights,
        or both during a simulation.
    modulatory : bool
        A boolean indicating if the connection is modulatory.

        Modulatory connections do not impart current in ``post``.
        Instead, it can be used by ``post`` to do other operations
        (e.g., modulate learning).

    See Also
    --------
    Model.connect : Helper to make connections
    Model.connect_neurons : Helper to make direct connections

    """

    def __init__(self, pre, post, transform=1.0, weights=None, decoders=None,
                 filter=None, function=None, learning_rule=None,
                 eval_points=None, modulatory=False):
        if weights is not None:
            raise NotImplementedError()
        if decoders is not None:
            raise NotImplementedError()
        if filter is not None:
            raise NotImplementedError()
        if learning_rule is not None:
            raise NotImplementedError()

        # if function is None:
        #     function = lambda x: x

        if eval_points is None:
            eval_points = pre.babbling_signal ## TODO: eval_points ensemble prop

        self.pre = pre
        self.post = post

        if function is None:
            targets = eval_points.T
        else:
            targets = np.array([function(s) for s in eval_points.T])
            if len(targets.shape) < 2:
                targets.shape = targets.shape[0], 1

        n, = targets.shape[1:]
        dt = pre.model.dt

        # -- N.B. this is only accurate for models firing well
        #    under the simulator's dt.
        A = pre.neurons.babbling_rate * dt
        b = targets
        weights, res, rank, s = np.linalg.lstsq(A, b, rcond=rcond)

        sig = ensemble.model.add(Signal(n=n, name='%s[%i]' % (name, ii)))
        decoder = ensemble.model.add(Decoder(
                sig=sig,
                pop=ensemble.neurons[ii],
                weights=weights.T))

        # set up self.sig as an unfiltered signal
        transform = ensemble.model.add(Transform(1.0, sig, sig))

        self.sigs.append(sig)
        self.decoders.append(decoder)
        self.transforms.append(transform)


        # if isinstance(self.pre, Ensemble):
        #     self.decoder = sim.Decoder(self.pre.nl, self.pre.sig)
        #     self.decoder.desired_function = function
        #     self.transform = sim.Transform(np.asarray(transform),
        #                                   self.pre.sig,
        #                                   self.post.sig)

        # elif isinstance(self.pre, Node):
        #     if function is None:
        #         self.transform = sim.Transform(np.asarray(transform),
        #                                       self.pre.sig,
        #                                       self.post.sig)
        #     else:
        #         raise NotImplementedError()
        # else:
        #     raise NotImplementedError()

    def __str__(self):
        ret = "Connection (id " + str(id(self)) + "): \n"
        if hasattr(self, 'decoder'):
            return ret + ("    " + str(self.decoder) + "\n"
                          "    " + str(self.transform))
        else:
            return ret + "    " + str(self.transform)

    def __repr__(self):
        return str(self)

    @property
    def name(self):
        return self.pre.name + ">" + self.post.name

    def add_to_model(self, model):
        if hasattr(self, 'decoder'):
            model.add(self.decoder)
        if hasattr(self, 'transform'):
            model.add(self.transform)
        if hasattr(self, 'filter'):
            model.add(self.filter)

    def remove_from_model(self, model):
        raise NotImplementedError


# class Probe(object):
#     def __init__(self, target, sample_every=None, filter=None):
#         if pstc is not None and pstc > self.dt:
#             fcoef, tcoef = _filter_coefs(pstc=pstc, dt=self.dt)
#             probe_sig = self.signal(obj.sig.n)
#             self.filter(fcoef, probe_sig, probe_sig)
#             self.transform(tcoef, obj.sig, probe_sig)
#             self.probe = SimModel.probe(self, probe_sig, sample_every)


#     @staticmethod
#     def filter_coefs(pstc, dt):
#         pstc = max(pstc, dt)
#         decay = math.exp(-dt / pstc)
#         return decay, (1.0 - decay)


### Low-level objects

"""
simulator_objects.py: model description classes

These classes are used to describe a Nengo model to be simulated.
Model is the input to a *simulator* (see e.g. simulator.py).

"""
import numpy as np


random_weight_rng = np.random.RandomState(12345)

"""
Set assert_named_signals True to raise an Exception
if model.signal is used to create a signal with no name.

This can help to identify code that's creating un-named signals,
if you are trying to track down mystery signals that are showing
up in a model.
"""
assert_named_signals = False


class ShapeMismatch(ValueError):
    pass


class TODO(NotImplementedError):
    """Potentially easy NotImplementedError"""


class SignalView(object):
    """Interpretable, vector-valued quantity within NEF
    """
    def __init__(self, base, shape, elemstrides, offset, name=None):
        assert base
        self.base = base
        self.shape = tuple(shape)
        self.elemstrides = tuple(elemstrides)
        self.offset = int(offset)
        if name is not None:
            self._name = name

    def __len__(self):
        return self.shape[0]

    def __str__(self):
        return '%s{%s, %s}' % (
            self.__class__.__name__,
            self.name, self.shape)

    def __repr__(self):
        return '%s{%s, %s}' % (
            self.__class__.__name__,
            self.name, self.shape)

    @property
    def dtype(self):
        return np.dtype(self.base._dtype)

    @property
    def ndim(self):
        return len(self.shape)

    @property
    def size(self):
        return int(np.prod(self.shape))

    def reshape(self, *shape):
        if len(shape) == 1 and isinstance(shape[0], (list, tuple)):
            shape = shape[0]
        if self.elemstrides == (1,):
            size = int(np.prod(shape))
            if size != self.size:
                raise ShapeMismatch(shape, self.shape)
            elemstrides = [1]
            for si in reversed(shape[1:]):
                elemstrides = [si * elemstrides[0]] + elemstrides
            return SignalView(
                base=self.base,
                shape=shape,
                elemstrides=elemstrides,
                offset=self.offset)
        else:
            # -- there are cases where reshaping can still work
            #    but there are limits too, because we can only
            #    support view-based reshapes. So the strides have
            #    to work.
            raise TODO('reshape of strided view')

    def transpose(self, neworder=None):
        raise TODO('transpose')

    def __getitem__(self, item):
        # -- copy the shape and strides
        shape = list(self.shape)
        elemstrides = list(self.elemstrides)
        offset = self.offset
        if isinstance(item, (list, tuple)):
            dims_to_del = []
            for ii, idx in enumerate(item):
                if isinstance(idx, int):
                    dims_to_del.append(ii)
                    offset += idx * elemstrides[ii]
                elif isinstance(idx, slice):
                    start, stop, stride = idx.indices(shape[ii])
                    offset += start * elemstrides[ii]
                    if stride != 1:
                        raise NotImplementedError()
                    shape[ii] = stop - start
            for dim in reversed(dims_to_del):
                shape.pop(dim)
                elemstrides.pop(dim)
            return SignalView(
                base=self.base,
                shape=shape,
                elemstrides=elemstrides,
                offset=offset)
        elif isinstance(item, (int, np.integer)):
            if len(self.shape) == 0:
                raise IndexError()
            if not (0 <= item < self.shape[0]):
                raise NotImplementedError()
            shape = self.shape[1:]
            elemstrides = self.elemstrides[1:]
            offset = self.offset + item * self.elemstrides[0]
            return SignalView(
                base=self.base,
                shape=shape,
                elemstrides=elemstrides,
                offset=offset)
        elif isinstance(item, slice):
            return self.__getitem__((item,))
        else:
            raise NotImplementedError(item)

    @property
    def name(self):
        try:
            return self._name
        except AttributeError:
            if self.base is self:
                return '<anon>'
            else:
                return 'View(%s)' % self.base.name

    @name.setter
    def name(self, value):
        self._name = value



class Signal(SignalView):
    """Interpretable, vector-valued quantity within NEF"""
    def __init__(self, n=1, dtype=np.float64, name=None):
        self.n = n
        self._dtype = dtype
        if name is not None:
            self._name = name
        if assert_named_signals:
            assert name

    def __str__(self):
        return "Signal (" + str(self.n) + "D, id " + str(id(self)) + ")"

    def __repr__(self):
        return str(self)

    @property
    def shape(self):
        return (self.n,)

    @property
    def elemstrides(self):
        return (1,)

    @property
    def offset(self):
        return 0

    @property
    def base(self):
        return self

    def add_to_model(self, model):
        model.signals.add(self)


class Probe(object):
    """A model probe to record a signal"""
    def __init__(self, sig, dt):
        self.sig = sig
        self.dt = dt

    def __str__(self):
        return "Probing " + str(self.sig)

    def __repr__(self):
        return str(self)

    def add_to_model(self, model):
        model.probes.add(self)



class Constant(Signal):
    """A signal meant to hold a fixed value"""
    def __init__(self, n, value, name=None):
        Signal.__init__(self, n, name=name)
        self.value = np.asarray(value)
        # TODO: change constructor to get n from value
        assert self.value.size == n

    def __str__(self):
        return "Constant (" + str(self.value) + ", id " + str(id(self)) + ")"

    def __repr__(self):
        return str(self)

    @property
    def shape(self):
        return self.value.shape

    @property
    def elemstrides(self):
        s = np.asarray(self.value.strides)
        return tuple(map(int, s / self.dtype.itemsize))


class Transform(object):
    """A linear transform from a decoded signal to the signals buffer"""
    def __init__(self, alpha, insig, outsig):
        alpha = np.asarray(alpha)
        if hasattr(outsig, 'value'):
            raise TypeError('transform destination is constant')
        self.alpha_signal = Constant(n=alpha.size,
                                     value=alpha,
                                     name='tf_alpha')
        self.insig = insig
        self.outsig = outsig
        if self.alpha_signal.size == 1:
            if self.insig.shape != self.outsig.shape:
                raise ShapeMismatch()
        else:
            if self.alpha_signal.shape != (
                    self.outsig.shape + self.insig.shape):
                raise ShapeMismatch(
                        self.alpha_signal.shape,
                        self.insig.shape,
                        self.outsig.shape,
                        )

    def __str__(self):
        return ("Transform (id " + str(id(self)) + ")"
                " from " + str(self.insig) + " to " + str(self.outsig))

    def __repr__(self):
        return str(self)

    @property
    def alpha(self):
        return self.alpha_signal.value

    @alpha.setter
    def alpha(self, value):
        self.alpha_signal.value[...] = value

    def add_to_model(self, model):
        model.signals.add(self.alpha_signal)
        model.transforms.add(self)


class Filter(object):
    """A linear transform from signals[t-1] to signals[t]"""
    def __init__(self, alpha, oldsig, newsig):
        if hasattr(newsig, 'value'):
            raise TypeError('filter destination is constant')
        alpha = np.asarray(alpha)
        self.alpha_signal = Constant(n=alpha.size, value=alpha,
                                     name='f_alpha')
        self.oldsig = oldsig
        self.newsig = newsig

        if self.alpha_signal.size == 1:
            if self.oldsig.shape != self.newsig.shape:
                raise ShapeMismatch(
                        self.alpha_signal.shape,
                        self.oldsig.shape,
                        self.newsig.shape,
                        )
        else:
            if self.alpha_signal.shape != (
                    self.newsig.shape + self.oldsig.shape):
                raise ShapeMismatch(
                        self.alpha_signal.shape,
                        self.oldsig.shape,
                        self.newsig.shape,
                        )

    def __str__(self):
        return ("Filter (id " + str(id(self)) + ")"
                " from " + str(self.oldsig) + " to " + str(self.newsig))

    def __repr__(self):
        return str(self)

    @property
    def alpha(self):
        return self.alpha_signal.value

    @alpha.setter
    def alpha(self, value):
        self.alpha_signal.value[...] = value

    def add_to_model(self, model):
        model.signals.add(self.alpha_signal)
        model.filters.add(self)


class Encoder(object):
    """A linear transform from a signal to a population"""
    def __init__(self, sig, pop, weights=None):
        self.sig = sig
        self.pop = pop
        if weights is None:
            weights = random_weight_rng.randn(pop.n_in, sig.size)
        else:
            weights = np.asarray(weights)
            if weights.shape != (pop.n_in, sig.size):
                raise ValueError('weight shape', weights.shape)
        self.weights_signal = Constant(n=weights.size, value=weights)

    def __str__(self):
        return ("Encoder (id " + str(id(self)) + ")"
                " of " + str(self.sig) + " to " + str(self.pop))

    def __repr__(self):
        return str(self)

    @property
    def weights(self):
        return self.weights_signal.value

    @weights.setter
    def weights(self, value):
        self.weights_signal.value[...] = value

    def add_to_model(self, model):
        model.encoders.add(self)
        model.signals.add(self.weights_signal)


class Decoder(object):
    """A linear transform from a population to a signal"""
    def __init__(self, pop, sig, weights=None):
        self.pop = pop
        self.sig = sig
        if weights is None:
            weights = random_weight_rng.randn(sig.size, pop.n_out)
        else:
            weights = np.asarray(weights)
            if weights.shape != (sig.size, pop.n_out):
                raise ValueError('weight shape', weights.shape)
        self.weights_signal = Constant(n=weights.size, value=weights)

    def __str__(self):
        return ("Decoder (id " + str(id(self)) + ")"
                " of " + str(self.pop) + " to " + str(self.sig))

    def __repr__(self):
        return str(self)

    @property
    def weights(self):
        return self.weights_signal.value

    @weights.setter
    def weights(self, value):
        self.weights_signal.value[...] = value

    def add_to_model(self, model):
        model.decoders.add(self)
        model.signals.add(self.weights_signal)


### Nonlinearities

# Definitions of standard kinds of Non-Linearity

# TODO: Consider moving these into simulator_objects.py
# because they are the basic objects that are destinations for
# e.g. encoders and sources for decoders. They are tightly
# part of that set of objects.
#

class Nonlinearity(object):
    def __str__(self):
        return "Nonlinearity (id " + str(id(self)) + ")"

    def __repr__(self):
        return str(self)

    def add_to_model(self, model):
        model.nonlinearities.add(self)
        model.signals.add(self.bias_signal)
        model.signals.add(self.input_signal)
        model.signals.add(self.output_signal)


class Direct(Nonlinearity):
    def __init__(self, n_in, n_out, fn, name=None):
        """
        fn:
        """
        if name is None:
            self.input_signal = Signal(n_in)
            self.output_signal = Signal(n_out)
            self.bias_signal = Constant(n=n_in, value=np.zeros(n_in))
        else:
            self.input_signal = Signal(n_in,
                                      name=name + '.input')
            self.output_signal = Signal(n_out,
                                       name=name + '.output')
            self.bias_signal = Constant(n=n_in,
                                        value=np.zeros(n_in),
                                       name=name + '.bias')

        self.n_in = n_in
        self.n_out = n_out
        self.fn = fn

    def __str__(self):
        return "Direct (id " + str(id(self)) + ")"

    def __repr__(self):
        return str(self)

    def fn(self, J):
        return J


class LIF(Nonlinearity):
    def __init__(self, n_neurons, tau_rc=0.02, tau_ref=0.002, upsample=1,
                name=None):
        if name is None:
            self.input_signal = Signal(n_neurons)
            self.output_signal = Signal(n_neurons)
            self.bias_signal = Constant(n=n_neurons, value=np.zeros(n_neurons))
        else:
            self.input_signal = Signal(n_neurons, name=name + '.input')
            self.output_signal = Signal(n_neurons, name=name + '.output')
            self.bias_signal = Constant(n=n_neurons,
                                        value=np.zeros(n_neurons),
                                       name=name + '.bias')

        self.n_neurons = n_neurons
        self.upsample = upsample
        self.tau_rc = tau_rc
        self.tau_ref = tau_ref
        self.gain = np.random.rand(n_neurons)

    def __str__(self):
        return "LIF (id " + str(id(self)) + ", " + str(self.n_neurons) + "N)"

    def __repr__(self):
        return str(self)

    @property
    def bias(self):
        return self.bias_signal.value

    @bias.setter
    def bias(self, value):
        self.bias_signal.value[...] = value

    @property
    def n_in(self):
        return self.n_neurons

    @property
    def n_out(self):
        return self.n_neurons

    def set_gain_bias(self, max_rates, intercepts):
        """Compute the alpha and bias needed to get the given max_rate
        and intercept values.

        Returns gain (alpha) and offset (j_bias) values of neurons.

        Parameters
        ---------
        max_rates : list of floats
            Maximum firing rates of neurons.
        intercepts : list of floats
            X-intercepts of neurons.

        """
        max_rates = np.asarray(max_rates)
        intercepts = np.asarray(intercepts)
        x = 1.0 / (1 - np.exp(
            (self.tau_ref - (1.0 / max_rates)) / self.tau_rc))
        self.gain = (1 - x) / (intercepts - 1.0)
        self.bias = 1 - self.gain * intercepts

    def step_math0(self, dt, J, voltage, refractory_time, spiked):
        if self.upsample != 1:
            raise NotImplementedError()

        # N.B. J here *includes* bias

        # Euler's method
        dV = dt / self.tau_rc * (J - voltage)

        # increase the voltage, ignore values below 0
        v = np.maximum(voltage + dV, 0)

        # handle refractory period
        post_ref = 1.0 - (refractory_time - dt) / dt

        # set any post_ref elements < 0 = 0, and > 1 = 1
        v *= np.clip(post_ref, 0, 1)

        # determine which neurons spike
        # if v > 1 set spiked = 1, else 0
        spiked[:] = (v > 1) * 1.0

        old = np.seterr(all='ignore')
        try:

            # linearly approximate time since neuron crossed spike threshold
            overshoot = (v - 1) / dV
            spiketime = dt * (1.0 - overshoot)

            # adjust refractory time (neurons that spike get a new
            # refractory time set, all others get it reduced by dt)
            new_refractory_time = spiked * (spiketime + self.tau_ref) \
                                  + (1 - spiked) * (refractory_time - dt)
        finally:
            np.seterr(**old)

        # return an ordered dictionary of internal variables to update
        # (including setting a neuron that spikes to a voltage of 0)

        voltage[:] = v * (1 - spiked)
        refractory_time[:] = new_refractory_time

    def rates(self, J_without_bias):
        """Return LIF firing rates for current J in Hz

        Parameters
        ---------
        J: ndarray of any shape
            membrane voltages
        tau_rc: broadcastable like J
            XXX
        tau_ref: broadcastable like J
            XXX
        """
        old = np.seterr(all='ignore')
        J = J_without_bias + self.bias
        try:
            A = self.tau_ref - self.tau_rc * np.log(
                1 - 1.0 / np.maximum(J, 0))
            # if input current is enough to make neuron spike,
            # calculate firing rate, else return 0
            A = np.where(J > 1, 1 / A, 0)
        finally:
            np.seterr(**old)
        return A


class LIFRate(LIF):
    def __init__(self, n_neurons):
        LIF.__init__(self, n_neurons)
        self.input_signal = Signal(n_neurons)
        self.output_signal = Signal(n_neurons)
        self.bias_signal = Constant(n=n_neurons, value=np.zeros(n_neurons))

    def __str__(self):
        return "LIFRate (id " + str(id(self)) + ", " + str(self.n_neurons) + "N)"

    def __repr__(self):
        return str(self)

    @property
    def n_in(self):
        return self.n_neurons

    @property
    def n_out(self):
        return self.n_neurons
